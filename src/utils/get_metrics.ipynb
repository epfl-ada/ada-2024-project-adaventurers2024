{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame shape: (49555, 28)\n",
      "\n",
      "After removing rows with vote_count = 0: (42075, 28)\n",
      "\n",
      "After removing rows with vote_average = 0: (42058, 28)\n",
      "After removing rows with revenue = 0: (7482, 28)\n",
      "After removing duplicate movies: (7452, 28)\n",
      "\n",
      "Selected relevant columns: (7452, 6)\n",
      "\n",
      "After removing movies with budget <= 0: (5661, 7)\n",
      "\n",
      "After removing outliers in 'vote_average': 83 rows removed, remaining 5578 rows\n",
      "\n",
      "After removing outliers in 'revenue': 609 rows removed, remaining 4969 rows\n",
      "\n",
      "After removing outliers in 'ROI': 485 rows removed, remaining 4484 rows\n",
      "\n",
      "Randomly selected 200 movies for analysis.\n",
      "\n",
      "Processing complete. 'metrics.json' has been created with the selected subset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ------------------------ #\n",
    "# 1. Load the Dataset\n",
    "# ------------------------ #\n",
    "\n",
    "df = pd.read_csv('../../data/cmu_tmdb.csv')\n",
    "print(\"Initial DataFrame shape:\", df.shape)\n",
    "\n",
    "# ------------------------ #\n",
    "# 2. Data Cleaning\n",
    "# ------------------------ #\n",
    "\n",
    "# 2.1 Remove rows where vote_average is 0\n",
    "df = df[df['vote_count'] > 0]\n",
    "print(\"\\nAfter removing rows with vote_count = 0:\", df.shape)\n",
    "df = df[df['vote_average'] > 0]\n",
    "print(\"\\nAfter removing rows with vote_average = 0:\", df.shape)\n",
    "\n",
    "# 2.2 Remove rows where revenue is 0\n",
    "df = df[df[\"revenue\"] > 0]\n",
    "print(\"After removing rows with revenue = 0:\", df.shape)\n",
    "\n",
    "# 2.3 Remove duplicate movies based on 'id'\n",
    "df = df.drop_duplicates(subset=\"id\")\n",
    "print(\"After removing duplicate movies:\", df.shape)\n",
    "\n",
    "# ------------------------ #\n",
    "# 3. Select Relevant Columns\n",
    "# ------------------------ #\n",
    "\n",
    "relevant_cols = [\"id\", \"title\", \"vote_average\", \"vote_count\", \"revenue\", \"budget\"]\n",
    "df = df[relevant_cols].copy()\n",
    "print(\"\\nSelected relevant columns:\", df.shape)\n",
    "\n",
    "# ------------------------ #\n",
    "# 4. Compute Additional Metrics\n",
    "# ------------------------ #\n",
    "\n",
    "# Compute profit\n",
    "df[\"profit\"] = df[\"revenue\"] - df[\"budget\"]\n",
    "\n",
    "# Remove movies with budget <= 0 to avoid division by zero or negative ROI\n",
    "df = df[df[\"budget\"] > 0]\n",
    "print(\"\\nAfter removing movies with budget <= 0:\", df.shape)\n",
    "\n",
    "# Compute ROI\n",
    "df[\"ROI\"] = df[\"profit\"] / df[\"budget\"]\n",
    "\n",
    "# ------------------------ #\n",
    "# 5. Remove Outliers\n",
    "# ------------------------ #\n",
    "\n",
    "def remove_outliers_iqr(data, col):\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "# Remove outliers for relevant columns\n",
    "columns_to_check = [\"vote_average\", \"revenue\", \"ROI\"]\n",
    "for col in columns_to_check:\n",
    "    before = df.shape[0]\n",
    "    df = remove_outliers_iqr(df, col)\n",
    "    after = df.shape[0]\n",
    "    print(\n",
    "        f\"\\nAfter removing outliers in '{col}': {before - after} rows removed, remaining {after} rows\"\n",
    "    )\n",
    "\n",
    "# ------------------------ #\n",
    "# 6. Randomly Select Subset of Movies\n",
    "# ------------------------ #\n",
    "\n",
    "# Set sample size (e.g., 200 movies) and random state for reproducibility\n",
    "sample_size = 200\n",
    "df_sample = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"\\nRandomly selected {sample_size} movies for analysis.\")\n",
    "\n",
    "# ------------------------ #\n",
    "# 7. Save Processed Data as JSON\n",
    "# ------------------------ #\n",
    "\n",
    "# Convert sampled DataFrame to dictionary\n",
    "processed_data = df_sample.to_dict(orient='records')\n",
    "\n",
    "# Save to 'metrics.json'\n",
    "with open(\"../../docs/assets/data/metrics.json\", \"w\") as f:\n",
    "    json.dump(processed_data, f, indent=2)\n",
    "\n",
    "print(\"\\nProcessing complete. 'metrics.json' has been created with the selected subset.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
